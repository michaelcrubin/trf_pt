
## Rain Events {#sec-energy-intro .unnumbered}



\
\

::: {.callout-tip title="Temporal dependence of Rain events"}
To move from hourly rain time series to **independent rain events**, we define and detect rain events using a memory-informed, smoothed and threshold-driven approach. This method ensures that detected events represent coherent meteorological systems, while ensuring *iid*. The smoothing effect, which includes a time-padding, also allows for a time-tolerance when comparing models to stations.
:::

\
\
\



### Core Principles

Our guiding principle is to develop a tolerant, but information rich metric system. By intuition, if a model preducts a rain few hours to early, it should be less punished than of it predicts to little.

- **Memory timescale ($\tau$):** Derived as in the previous section, $\tau$ indicates the number of hours after which precipitation values can be considered approximately independent.
- **Smoothing:** Short-term fluctuations are smoothed using a rolling mean of window size $k=\tau/(2+1)$.
- **Event padding:** The shoothing effect also ensures that we have a padding-effect of length at both ends of the event.
- **Dry gap threshold:** We define an **event boundary** whenever there is a dry spell lasting more than $\tau / 2$.
- **Event filter:** Events with total accumulated rain per event below a defined minimum $min =5$ are discarded.

\

### Detailed Procedure

Given an input time series $X(t)$ of hourly rain data (station and models), we perform the following:

1. **Compute memory decay ($\tau$)**:  
   - Use `compute_tau_per_station(X)` to estimate the decorrelation scale.
   - This yields a time window beyond which memory can be assumed negligible.

2. **Define smoothing window**:  
   - Compute smoothing length: $k = \tau / \text{padding} + 1$
   - Apply centered **rolling mean** with window size $k$.

3. **Dry gap identification**:  
   - Mark time points where `station < threshold` as dry.
   - Consecutive dry hours are grouped and numbered (`gap_no`, `gap_i`).
   - A new event is **initiated** after any dry gap longer than $\tau / 2$.

4. **Assign event IDs**:  
   - Each block of rain data between dry gaps is assigned an `event_id`.

5. **Aggregate event totals**:  
   - For each event, compute total rain for station and each valid model.
   - Only retain events where:
     - No missing values across models
     - Total rain (`label_station`) exceeds `sum_threshold`

6. **Final filtering**:  
   - Drop all remaining rows with invalid or negative station data (e.g., placeholder -999).

This procesure is applied to the station values and all models.

\



\

### Example

Here, we simulate some examples.
As a first step, we extract the data, which look as follows:


```{r}
#| warning: false
#| eval: true
#| echo: false
#| message: false

library(here)
source(here("scripts", "helpers.R"))
source(here("scripts", "memory_funcs.R"))
# IMPORT AND SELECT DATA
var_id <- "rain_hour"
country <- "switzerland"
suffix <- "w_mb"

lcs <- available_locs(var_id, country, suffix)
lcs <- sample(lcs, 4)
data <- open_data(var_id, country, suffix, loc_id = lcs) %>%
  dplyr::mutate(year = lubridate::year(timestamp)) %>% 
  dplyr::filter(year >= 2022)
head(data)
```


\

Next, we run the event caculation as show below and plot some time series.

\

```{r}
#| warning: false
#| eval: true
#| echo: true
#| message: false


# defines a gap number aufzählen
calc_gap_no <- function(is_gap){
  x <- is_gap
  y = c(1, as.integer(x > lag(x))[-1])
  cumsum(y) * x
}

# gives event an id
calc_event_id <- function(gap_i, dry_gap){
  x =  as.integer(gap_i <= dry_gap)
  y = c(0, as.integer(x > lag(x))[-1])
  cumsum(y) * x
}

# returns the colums which have valid entries (no NA and gaps)
get_valid_models <- function(X, base_cols, na_threshold = 0.1) {
  X %>%
    dplyr::select(-any_of(base_cols)) %>%
    summarise(across(everything(), ~ mean(!is.na(.x)))) %>%
    pivot_longer(everything(), names_to = "model", values_to = "coverage") %>%
    dplyr::filter(coverage >= (1 - na_threshold)) %>%
    pull(model)
}



# MAIN: runs the rain event 
rain_event_detector <- function(data, rain_threshold = 5, padding = 2, sum_threshold = 5, ... ){
  ## calc tau / decay of memory, i.e. when i can consider time points as memoryless
  tau_hour <- compute_tau_per_station(data) %>% dplyr::pull()

  # col handling
  base_cols <- c("timestamp", "loc_id", "station", "year")
  model_cols <- get_valid_models(data, base_cols)

  # Smoothing rolling mean to suppress noise + padding of events left right
  k <- round(tau_hour / padding + 1, 0)
  # Find start of new events based on dry gap ≥ tau/2
  dry_gap <- tau_hour / 2
  # correct threshold because of rollmean
  rain_threshold = rain_threshold * (2 / k)

  Y <- data %>%
    dplyr::arrange(timestamp) %>%
    dplyr::mutate(across(all_of(c("station", model_cols)), ~ round(zoo::rollmean(.x, k = k, fill = NA, align = "center"), 3))) %>%
    tidyr::drop_na(station) %>%
    # get gaps and number them
    dplyr::mutate(
      is_gap = station < rain_threshold,
      gap_no = calc_gap_no(is_gap)
    ) %>% 
    dplyr::group_by(gap_no) %>%
    dplyr::mutate(gap_i = cumsum(is_gap))%>%
    dplyr::ungroup() %>%
    # from gap after memory fades, make event
    dplyr::mutate(
      event_id = calc_event_id(gap_i, dry_gap)
    ) %>%
    dplyr::group_by(event_id) %>% 
    # sum all models and staitons per event
    dplyr::mutate(across(all_of(c("station", model_cols)), ~ sum(.x, na.rm = TRUE), .names = "label_{.col}")) %>%
    dplyr::filter(!any(is.na(across(model_cols)))) %>% # drops all events where we have NA entres
    dplyr::ungroup() %>%
    dplyr::mutate(event_id = event_id *  as.integer(label_station >= sum_threshold)) %>% # make sure we count as events only when sum is large enough
    # get rid of emoty data
    dplyr:::filter(station >= 0) %>% # i can filter the -999 out here because they are anyway no events
    dplyr::select(event_id, timestamp, station, any_of(model_cols))
  
  return(Y)
  
}

# runs the evaluation process for 1 station and 1 year
RUN_event <- function(data, loc_id, year, ...){
  Y <- data %>% rain_event_detector(rain_threshold = 0.01, padding = 1, sum_threshold = 5 )
  p <- plot_spaghetti(Y, loc_id, year)
  return(p)
}


grouper_vars <- c( "loc_id", "year")
result <- data %>% 
  dplyr::mutate(year = lubridate::year(timestamp)) %>%
    # dplyr::filter(year > 2022) %>%
    # dplyr::filter(loc_id %in% lcs[1:10]) %>% 
    tidyr::nest(data = -all_of(grouper_vars)) %>%
    dplyr::mutate(p = purrr::pmap(., .f = RUN_event))%>%
    dplyr::select(all_of(c(grouper_vars, "p")))

```


```{r}
#| echo: false
#| results: asis
#| warning: false
#| message: false


htmlwidgets::saveWidget(result[["p"]][[1]], file = "../www/graph/timeseries1.html", selfcontained = TRUE)
htmlwidgets::saveWidget(result[["p"]][[2]], file = "../www/graph/timeseries2.html", selfcontained = TRUE)
htmlwidgets::saveWidget(result[["p"]][[6]], file = "../www/graph/timeseries3.html", selfcontained = TRUE)
htmlwidgets::saveWidget(result[["p"]][[8]], file = "../www/graph/timeseries4.html", selfcontained = TRUE)
htmlwidgets::saveWidget(result[["p"]][[12]], file = "../www/graph/timeseries5.html", selfcontained = TRUE)


cat(glue::glue('<iframe src="../www/graph/timeseries1.html" width="100%" height="600px" style="border:none;"></iframe>'))
cat(glue::glue('<iframe src="../www/graph/timeseries2.html" width="100%" height="600px" style="border:none;"></iframe>'))
cat(glue::glue('<iframe src="../www/graph/timeseries3.html" width="100%" height="600px" style="border:none;"></iframe>'))
cat(glue::glue('<iframe src="../www/graph/timeseries4.html" width="100%" height="600px" style="border:none;"></iframe>'))
cat(glue::glue('<iframe src="../www/graph/timeseries5.html" width="100%" height="600px" style="border:none;"></iframe>'))

```




\
\

\

::: {.callout-note title="Intuition"}
We can observe the rain events by the shaded sections. The events are consistent with the intuition. Note that the straight lines from one to the next event mean that there are NA values (instead of 0) in between, i.e. data gaps. Note that for the analysis, only the events, which are shaded, are taken into account. The remaining hours are filtered out.
:::

\
\


